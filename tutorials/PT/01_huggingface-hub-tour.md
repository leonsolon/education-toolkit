# Workshop: Um tour pelo Hugging Face Hub

<aside>

üí° **Bem-vindo!**

Montamos um kit de ferramentas que os instrutores universit√°rios podem usar para preparar facilmente laborat√≥rios, trabalhos de casa ou aulas. O conte√∫do √© projetado de forma independente, de modo que possa ser facilmente incorporado ao curr√≠culo existente. Este conte√∫do √© **gratuito** e usa tecnologias Open Source amplamente conhecidas (`transformers`, `gradio`, etc).

Como alternativa, voc√™ pode solicitar que algu√©m da equipe do Hugging Face execute os tutoriais para sua turma por meio do [ML demo.cratization tour](https://www.notion.so/ML-Demo-cratization-tour-with-66847a294abd4e9785e85663f5239652 ) iniciativa!

Voc√™ pode encontrar todos os tutoriais e recursos que reunimos [aqui](https://www.notion.so/Education-Toolkit-7b4a9a9d65ee4a6eb16178ec2a4f3599).

</aside>

**Dura√ß√£o:** 20 a 40 minutos

**Objetivo:** aprender a usar com efici√™ncia a [plataforma Hub](http://hf.co) gratuita para poder colaborar no ecossistema e em equipes em projetos de Machine Learning (ML).

Metas de aprendizagem:

- Conhe√ßa e explore os mais de 30.000 modelos compartilhados no Hub.
- Aprenda maneiras eficientes de encontrar modelos e conjuntos de dados adequados para sua tarefa.
- Aprenda a contribuir e trabalhar de forma colaborativa.
- Explore demos de ML criadas pela comunidade.

**Formato:** laborat√≥rio curto ou para levar para casa

**P√∫blico:** alunos de qualquer forma√ß√£o interessados ‚Äã‚Äãem usar modelos existentes ou compartilhar seus modelos.

**Pr√©-requisitos**

- Compreens√£o de alto n√≠vel de Machine Learning.
- (Opcional, mas incentivado) Experi√™ncia com Git ([recurso](https://learngitbranching.js.org/))

## **Por que o Hub?**

O Hub √© uma plataforma central onde qualquer pessoa pode compartilhar e explorar modelos, conjuntos de dados e demonstra√ß√µes de ML. O problema de "resolver IA" n√£o ser√° resolvido por uma √∫nica empresa, mas por uma cultura de compartilhamento de conhecimento e recursos. Por isso, o Hub visa construir a cole√ß√£o mais extensa de modelos, conjuntos de dados e demonstra√ß√µes de c√≥digo aberto.

Aqui est√£o alguns fatos sobre o Hugging Face Hub:

- Existem mais de 30.000 modelos p√∫blicos.
- Existem modelos para Processamento de Linguagem Natural, Vis√£o Computacional, √Åudio/Fala e Aprendizagem por Refor√ßo!
- Existem modelos para mais de 180 idiomas.
- Qualquer biblioteca de ML pode aproveitar o Hub: desde TensorFlow e PyTorch at√© integra√ß√µes avan√ßadas com spaCy, SpeechBrain e 20 outras bibliotecas.

## Explorando um modelo

Vamos come√ßar a explora√ß√£o de modelos. Voc√™ pode acessar 30.000 modelos em [hf.co/models](http://hf.co/models). Voc√™ ver√° [gpt2](https://huggingface.co/gpt2) como um dos modelos com mais downloads. Vamos clicar nele.

O site levar√° voc√™ ao cart√£o do modelo quando voc√™ clicar em um modelo. Um cart√£o de modelo √© uma ferramenta que documenta modelos, fornecendo informa√ß√µes √∫teis sobre os modelos e sendo essencial para a descoberta e a reprodutibilidade.

A interface tem muitos componentes, ent√£o vamos analis√°-los:

[https://www.youtube.com/watch?v=XvSGPZFEjDY&feature=emb_imp_woyt](https://www.youtube.com/watch?v=XvSGPZFEjDY&feature=emb_imp_woyt)

- Na parte superior, voc√™ pode encontrar **tags** diferentes para coisas como a tarefa (*gera√ß√£o de texto, classifica√ß√£o de imagem* etc.), estruturas (*PyTorch*, *TensorFlow* etc.), a linguagem do modelo (*Ingl√™s*, *√Årabe*, *etc.*) e licen√ßa (*por exemplo, MIT*).

![](../../images/mode_card_tags.png)

- Na coluna da direita, voc√™ pode brincar com o modelo diretamente no navegador usando a *API de infer√™ncia*. O GPT2 √© um modelo de gera√ß√£o de texto, portanto, ele gerar√° texto adicional com uma entrada inicial. Tente digitar algo como "Era um dia claro e ensolarado".

![](../../images/model_card_inference_api.png)

- No meio, voc√™ pode percorrer o conte√∫do do cart√£o modelo. Ele tem se√ß√µes como Usos e limita√ß√µes pretendidos, Procedimento de treinamento e Informa√ß√µes de cita√ß√£o.

![](../../images/model_card_content.png)

De onde v√™m todos esses dados? No Hugging Face, tudo √© baseado em **reposit√≥rios Git** e √© de c√≥digo aberto. Voc√™ pode clicar na guia ‚ÄúArquivos e Vers√µes‚Äù, que permitir√° ver todos os arquivos do reposit√≥rio, incluindo os pesos do modelo. O cart√£o de modelo √© um arquivo markdown **([README.md](http://README.md))** que no topo do conte√∫do cont√©m metadados, como as tags.

![](../../images/model_card_git.png)

Como todos os modelos s√£o reposit√≥rios baseados em Git, voc√™ obt√©m controle de vers√£o pronto para uso. Assim como no GitHub, voc√™ pode fazer coisas como clonagem do Git, adi√ß√£o, confirma√ß√£o, ramifica√ß√£o e push. Se voc√™ nunca usou o Git antes, sugerimos o seguinte [recurso](https://learngitbranching.js.org/).

**Desafio 1**. Abra o arquivo `config.json` do reposit√≥rio GPT2. O arquivo de configura√ß√£o cont√©m hiperpar√¢metros, bem como informa√ß√µes √∫teis para carregar o modelo. A partir deste arquivo, responda:

- Qual √© a fun√ß√£o de ativa√ß√£o?
- Qual √© o tamanho do vocabul√°rio?

## **Explorando modelos**

At√© agora, exploramos um √∫nico modelo. Vamos selvagem! √Ä esquerda de [https://huggingface.co/models](https://huggingface.co/models), voc√™ pode filtrar por coisas diferentes:

- **Tarefas:** h√° suporte para dezenas de tarefas em diferentes dom√≠nios: Computador

## Adicionando um modelo

Digamos que voc√™ queira fazer upload de um modelo para o Hub. Este modelo pode ser um modelo de qualquer biblioteca de ML: Scikit-learn, Keras, Transformers, etc.

Vamos aos passos:

1. V√° para [huggingface.co/new](http://huggingface.co/new) para criar um novo reposit√≥rio de modelo. Os reposit√≥rios que voc√™ cria podem ser p√∫blicos ou privados.
2. Voc√™ come√ßa com um reposit√≥rio p√∫blico que possui um cart√£o modelo. Voc√™ pode carregar seu modelo usando a interface do usu√°rio da Web ou fazendo isso com o Git. Se voc√™ nunca usou o Git antes, sugerimos apenas usar a interface da Web. Voc√™ pode clicar em Adicionar arquivo e arrastar e soltar os arquivos que deseja adicionar. Se voc√™ quiser entender o fluxo de trabalho completo, vamos com a abordagem do Git.

    1. Instale o git e o git-lfs instalados em seu sistema.
        1. Git: [https://git-scm.com/book/en/v2/Getting-Started-Installing-Git](https://git-scm.com/book/en/v2/Getting-Started- Instalando-Git)
        2. Git-lfs: [https://git-lfs.github.com/](https://git-lfs.github.com/). Arquivos grandes precisam ser carregados com o Git LFS. O Git n√£o funciona bem quando seus arquivos est√£o acima de alguns megabytes, o que √© frequente no ML. Os modelos de ML podem ter at√© gigabytes ou terabytes! ü§Ø
    2. Clone o reposit√≥rio que voc√™ acabou de criar

        ``` python
        git clone https://huggingface.co/<your-username>/<your-model-id>
        ```

    3. V√° para o diret√≥rio e inicialize o Git LFS
        1. Opcional. N√≥s j√° fornecemos uma lista de extens√µes de arquivos comuns para os arquivos grandes em `.gitattributes`, Se os arquivos que voc√™ deseja enviar n√£o est√£o inclu√≠dos no arquivo `.gitattributes`, voc√™ pode precisar como mostrado aqui: Voc√™ pode fazer isso com

            ``` python
            git lfs faixa "*.your_extension"
            ```

            ``` python
             git lfs instalar
            ```

    4. Adicione seus arquivos ao reposit√≥rio. Os arquivos dependem da estrutura/bibliotecas que voc√™ est√° usando. No geral, o importante √© que voc√™ forne√ßa todos os artefatos necess√°rios para carregar o modelo. Por exemplo:
        1. Para o TensorFlow, voc√™ pode fazer upload de um arquivo SavedModel ou `h5`.
        2. Para PyTorch, geralmente, √© um `pytorch_model.bin`.
        3. Para o Scikit-Learn, geralmente √© um arquivo `joblib`.

        Aqui est√° um exemplo em Python salvando um arquivo de modelo Scikit-Learn.

        ``` python
        do sklearn import linear_model
        reg = linear_model.LinearRegression()
        reg.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])

        do dump de importa√ß√£o do joblib, carregue
        dump(reg, 'model.joblib')
        ```

    5. Confirme e envie seus arquivos (certifique-se de que o arquivo salvo esteja dentro do reposit√≥rio)

    ``` python
    gi adicionar.
    git commit -m "Primeira vers√£o do modelo"
    git push
    ```

E terminamos! Voc√™ pode verificar seu reposit√≥rio com todos os arquivos adicionados recentemente!

![](../../images/model_card_updated_repo.png)

A interface do usu√°rio permite explorar os arquivos de modelo e commits e ver o diff introduzido por cada commit.

**Desafio 4**. √â sua vez! Carregue um modelo fict√≠cio da biblioteca de sua escolha.

Agora que o modelo est√° no Hub, outros podem encontr√°-lo! Voc√™ tamb√©m pode colaborar facilmente com outras pessoas criando uma organiza√ß√£o. A hospedagem por meio do Hub permite que uma equipe atualize reposit√≥rios e fa√ßa coisas com as quais voc√™ est√° acostumado, como trabalhar em ramifica√ß√µes e trabalhar de forma colaborativa. O Hub tamb√©m permite o controle de vers√£o em seus modelos: se um ponto de verifica√ß√£o do modelo for interrompido repentinamente, voc√™ sempre poder√° voltar para uma vers√£o anterior.

No topo do `README`, voc√™ pode encontrar alguns metadados. Voc√™ s√≥ encontrar√° a licen√ßa agora, mas pode adicionar mais coisas. Vamos tentar alguns:

```yaml
 Tag:
- es #¬†Isso ser√° detectado automaticamente como uma tag de idioma.
- bert #¬†Voc√™ pode ter tags adicionais para filtragem
- text-classification #¬†Isso ser√° detectado automaticamente como uma tag de tarefa.
conjuntos de dados:
- llamas # Isso ser√° vinculado a um conjunto de dados no Hub, se ele existir.
```

**Desafio 5**. Usando a [documenta√ß√£o](https://huggingface.co/docs/hub/model-repos#how-are-model-tags-determinado), altere o exemplo padr√£o no widget.

Os metadados permitem que as pessoas descubram seu modelo rapidamente. Seu modelo agora aparecer√° quando voc√™ pesquisar modelos de classifica√ß√£o de texto em espanhol. O modelo tamb√©m aparecer√° ao olhar para o conjunto de dados.

Espere... conjuntos de dados?

## Conjuntos de dados

Com pipelines de ML, voc√™ geralmente tem um conjunto de dados para treinar o modelo. O Hub hospeda cerca de 3.000 conjuntos de dados de c√≥digo aberto e gratuitos para uso em v√°rios dom√≠nios. Al√©m disso, a [biblioteca] de `datasets` de c√≥digo aberto (https://huggingface.co/docs/datasets/) permite o uso f√°cil desses conjuntos de dados, incluindo grandes, usando recursos muito convenientes, como streaming. Este laborat√≥rio n√£o passar√° pela biblioteca, mas explica como explor√°-los.

Semelhante aos modelos, voc√™ pode acessar [https://hf.co/datasets](https://hf.co/datasets). √Ä esquerda, voc√™ pode encontrar diferentes filtros com base na tarefa, licen√ßa e tamanho do conjunto de dados.

Vamos explorar o conjunto de dados [GLUE](https://huggingface.co/datasets/glue), que √© um famoso conjunto de dados usado para testar o desempenho do modelo de PNL